{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting für Machine Learning\n",
    "\n",
    "Wir beschäftigen uns mit den grundlegenden Varianten des sogenannten _Boostings_.\n",
    "Dabei legen wir unser Augenmerk auf Boosting für die Klassifikation.\n",
    "Insbesondere klassifizieren wir Reden von deutschen Politikern, d.h. aus einem gegebenen Redetext ermitteln wir wer diese Rede hielt.\n",
    "(Diese Problemstellung war bereits Thema im den Übungen des [codecentric.AI](https://www.codecentric.de/kuenstliche-intelligenz/) Bootcamp zum Thema [Natural Language Processing](https://www.youtube.com/watch?v=GmLsb-o7hvM).)\n",
    "\n",
    "_Angenommen für unser Problem steht ein schlechter Klassifikator L zur Verfügung._\n",
    "_Wie können wir aus K einen guten Klassifikator L erzeugen?_\n",
    "\n",
    "Unter einem schlechten Klassifikator verstehen wir einen Klassifikator mit schlechter Vorhersagekraft, d.h. er macht viele Fehler.\n",
    "(Die Theorie erlaubt sogar so viele Fehler, dass die Kraft nur wenig besser als zufälliges Raten ist!)\n",
    "Der neue Klassifikator L wird keine abgewandelte Form von K sein, sondern L besteht aus mehreren geschickt kombinierten Instanzen von K.\n",
    "Daher bezeichnet man L auch als _Ensemble_.\n",
    "\n",
    "Ensembles lassen sich für unterschiedliche zugrunde liegende Typen von Klassifikatoren erstellen.\n",
    "Hier beschränken wir uns auf den Fall, dass K ein einfacher [Entscheidungsbaum-Klassifikator](https://en.wikipedia.org/wiki/Decision_tree_learning) ist.\n",
    "Die Klassifikation des Ensembles L ergibt sich aus den individuellen Klassifikationen der beteiligten Entscheidungsbäume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten laden\n",
    "\n",
    "Werfen wir zuerst einen Blick auf die Daten.\n",
    "Wir verwenden den von Barbaresi und Adrien bereitgestellten Datensatz [1], der unter der URL [2] verfügbar ist.\n",
    "\n",
    "[1] Barbaresi, Adrien (2018). \"A corpus of German political speeches from the 21st century\", Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), European Language Resources Association (ELRA), pp. 792–797.\n",
    "\n",
    "[2] http://purl.org/corpus/german-speeches\n",
    "\n",
    "Hier ein Einblick in wenige zufällig ausgewählte Reden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run define_load_data_functions.ipynb\n",
    "\n",
    "df = load_data()\n",
    "\n",
    "display(df.sample(n=len(df)).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Datensatz ist Angela Merkel mit der weitaus stärksten Anzahl von Reden vertreten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "speech_counts = df.person.value_counts()\n",
    "\n",
    "display(speech_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir beschränken uns auf die binäre Klassifikation, d.h. wir unterscheiden nur zwischen zwei Klassen von Personen.\n",
    "Um auf ausgewogenen Daten zu arbeiten wählen wir die Klassen _Angela Merkel_ und _Nicht Angela Merkel (Andere)_.\n",
    "Dazu vernachlässigen wir zuerst alle Personen, die mit nur wenigen Reden vertreten sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_NUM_SPEECHES = 100\n",
    "belowThreshold = lambda name: speech_counts[name] < MIN_NUM_SPEECHES\n",
    "\n",
    "dropped = filter(belowThreshold, speech_counts.index.tolist())\n",
    "df.drop(df[df.person.isin(dropped)].index, inplace=True)\n",
    "\n",
    "display(df.person.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dann fassen wir alle verbleibenden Personen zur Klasse _Andere_ zusammen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['person'] != \"Angela Merkel\", ['person']] = 'Andere'\n",
    "\n",
    "display(df.person.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten vorverarbeiten\n",
    "\n",
    "Es folgt eine Vorverarbeitung der Reden mit Hilfe der NLP-Bibliothek [spaCy](https://spacy.io/).\n",
    "In diesem Schritt zerlegen wir jede Rede in ihre (durch Whitespace getrennten) Bestandteile, die sogenannten _Tokens_.\n",
    "In dem Zuge entfernen wir Tokens mit geringer Information, wie z.B. Interpunktion und Stoppwörter (\"und\", \"der\", \"die\", \"das\", ...).\n",
    "Außerdem überführen wir jedes Token in seine Grundform, das sogenannte _Lemma_ (z.B. \"angekündigt\" -> \"ankündigen\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%run init_spacy.ipynb\n",
    "%run define_preprocessing.ipynb\n",
    "\n",
    "df = load_cached_or_preprocess(df.speech)\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für jede Rede R überführen wir nun die Folge von Lemmata von R in das \"Histogramm\" der Lemmahäufigkeiten von R.\n",
    "Bemerke, dass wir in diesem Schritt die der Reihenfolge Worte vergessen.\n",
    "(Man nennt solch eine vereinfachte Darstellung einer Wortfolge auch _bag of words_, um das Abhandensein von zeitlicher Information zu betonen.)\n",
    "\n",
    "Schauen wir uns ein paar Lemmata und die gewonnene Darstellung einer Rede im Detail an.\n",
    "(Einige Lemmata sind nicht \"perfekt\".\n",
    "Sie enthalten etwa Bindestriche oder liegen in gebeugter Form vor.\n",
    "Hier wird die Unschäfe der Sprache und ihrer Verarbeitung deutlich.\n",
    "Beispielsweise geschieht Lemmatisierung in spaCy nicht durch Anwendung eines Regelwerks, sondern durch neuronale Netze, die natürlich nicht in allen Fällen korrekte Ergebnisse erzielen.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%run define_feature_computation.ipynb\n",
    "\n",
    "(lemmata, lemma_index) = compute_index(df[\"lemmata\"])\n",
    "df[\"lemma_counts\"] = count(df[\"lemmata\"], lemma_index)\n",
    "\n",
    "display(lemmata[:10])\n",
    "display(df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Bis hier haben wir aus den Reden die für das Modell-Training benötigten statistischen Informationen extrahiert.\n",
    "Zum Start des Trainings fehlt nur noch die Konvertierung diese Informationen in das benötigte Eingabedatenformat.\n",
    "\n",
    "Zum Training nutzen wir die ML-Bibliothek [scikit-learn](https://scikit-learn.org/stable/).\n",
    "Die eingegebenen Trainingdaten bestehen aus einer Sammlung von sogenannten _Labels_ (eins pro Rede) und sogenannten _Featurevektoren_ (ebenfalls einer pro Rede).\n",
    "In unserem Fall gibt das Label einer Rede R an, welche Person die Rede R hielt (\"Angela Merkel\" oder \"Andere\").\n",
    "Der Feature-Vektor von R kodiert das Histogramm der Lemmahäufigkeiten von R (haben wir oben bereits berechnet).\n",
    "\n",
    "Für die Eingabe in die Algorithmen von scikit-learn werden alle Labels in einen Vektor zusammengefasst.\n",
    "Analog werden alle Featurevektoren zu einer Matrix zusammengefasst.\n",
    "Dafür müssen natürlich alle Featurevektoren die gleiche Länge haben, was wir mit Hilfe der Funktion `dict_to_sparse` erledigen.\n",
    "(Insbesondere gibt diese Funktion eine sogenannte _dünn besetzte Matrix_ aus, in der Einträge mit Wert Null nicht explizit gespeichert werden.\n",
    "Warum?\n",
    "In einer Rede erscheinen bei Weitem nicht alle möglichen Lemmata, folglich enthält jeder Featurevektor viele Nullen.\n",
    "Wir sparen also viel Speicherplatz.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%run define_conversion_functions.ipynb\n",
    "\n",
    "feature_vectors = dict_to_sparse(df[\"lemma_counts\"], len(lemma_index))\n",
    "categories = df[\"person\"].astype(\"category\")\n",
    "labels = categories.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Möge das Training beginnen.\n",
    "Erinnere, dass wir Ensembles von schwachen Klassifizierern erstellen möchten.\n",
    "Als schwachen Klassifizierer wählen wir einen sogenannten _Decision Stump_, d.h. einen Entscheidungsbaum der Tiefe 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def make_decision_stump():\n",
    "    return DecisionTreeClassifier(max_depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Warmwerden wenden wir zunächst den schwachen Klassifizierer an.\n",
    "\n",
    "Dabei zerlegen wir die Eingabedaten in Trainingdaten und Testdaten, und zwar im üblichen Verhältnis 70/30.\n",
    "Nur die Trainingsdaten werden für das tatsächliche Training verwendet.\n",
    "Mit Hilfe der Testdaten wird die Performance des trainierten Modells evaluiert.\n",
    "\n",
    "Damit wir die Performance verlässich evaluieren können, führen wir das Experiment nicht nur einmal durch, sondern wiederholen es und mitteln die Ergebnisse.\n",
    "Die _Accuracy_ zeigt uns wie viele Testdatensätze korrekt klassifiziert wurden.\n",
    "Die sogenannte _Confusion Matrix_ schlüsselt die korrekten und falschen Klassifizierungen auf (in der i-ten Zeile und j-ten Spalte steht wie viele Reden von \"i\" als Reden von \"j\" klassifiziert wurden).\n",
    "Wir sehen, dass nicht einmal 80% der Testdaten korrekt klassifiziert werden, wobei mehr Reden von Angela Merkel falsch klassifiziert wurden (über 30%) als Reden von anderen (ca. 10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run define_plot_functions.ipynb\n",
    "%run define_train_functions.ipynb\n",
    "\n",
    "TRAIN_TEST_RATIO = 0.3 # proportion of test data\n",
    "REPETITIONS = 20 # number of repetitions to average from\n",
    "\n",
    "# hier übergeben wir eine \"Generatorfunktion\",\n",
    "# welche wiederholt Klassifizierer erstellt\n",
    "(classifiers, accuracies, confusion_matrices) = train_and_test_repeated(\n",
    "    classifier_generator=make_decision_stump, \n",
    "    data=feature_vectors,\n",
    "    labels=labels,\n",
    "    test_size=TRAIN_TEST_RATIO,\n",
    "    repetitions=REPETITIONS)\n",
    "\n",
    "display_mean_accuracy(accuracies)\n",
    "display_mean_confusion_matrix(confusion_matrices, classes=categories.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ein wenig Gefühl zu bekommen, schauen wir uns einen der trainierten Decision Stumps etwas genauer an.\n",
    "Interessant ist insbesondere die erste Zeile des Wurzelknotens.\n",
    "Die Häufigkeit eines Lemmas bestimmt welchem der beiden Blätter eine Rede zugeordnet wird.\n",
    "Jedes Blatt klassifiziert alle ihm zugeordneten Reden mit der gleichen Person, wie die jeweils letzte Zeile zeigt.\n",
    "(Die Werte _gini_, _samples_ und _value_ zeigen die [Gini impurity](https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity), wie viele Reden dem jeweiligen Knoten zugeordnet werden bzw. die Redner-Verteilung aller dem Knoten zugeordneten Reden.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_decision_tree(classifiers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    "Die Performance des schwachen Decision Stumps können wir sicherlich verbessern.\n",
    "Erfreulich wird sein, mit welch einfachen Mitteln das gelingt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "BOOST_FACTOR = 20\n",
    "ALL_CORES = -1\n",
    "\n",
    "base = make_decision_stump()\n",
    "classifier = BaggingClassifier(base_estimator=base,\n",
    "                               n_estimators=BOOST_FACTOR,\n",
    "                               n_jobs=ALL_CORES)\n",
    "\n",
    "(accuracy, confusion) = train_and_test_with(classifier,\n",
    "                                            feature_vectors,\n",
    "                                            labels,\n",
    "                                            test_size=TRAIN_TEST_RATIO)\n",
    "\n",
    "display(accuracy)\n",
    "display_confusion_matrix(confusion, classes=categories.unique())\n",
    "for tree in classifier:\n",
    "    display_decision_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "base = make_decision_stump()\n",
    "classifier = AdaBoostClassifier(base_estimator=base,\n",
    "                                n_estimators=BOOST_FACTOR)\n",
    "\n",
    "(accuracy, confusion) = train_and_test_with(classifier,\n",
    "                                            feature_vectors,\n",
    "                                            labels,\n",
    "                                            test_size=TRAIN_TEST_RATIO)\n",
    "\n",
    "display(accuracy)\n",
    "plot_confusion_matrix(confusion, classes=categories.unique())\n",
    "for tree in classifier:\n",
    "    display_decision_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "\n",
    "base = make_decision_stump()\n",
    "classifier = XGBClassifier(max_depth=1,\n",
    "                           n_estimators=BOOST_FACTOR)\n",
    "\n",
    "(accuracy, confusion) = train_and_test_with(classifier,\n",
    "                                            feature_vectors,\n",
    "                                            labels,\n",
    "                                            test_size=TRAIN_TEST_RATIO)\n",
    "\n",
    "display(accuracy)\n",
    "plot_confusion_matrix(confusion, classes=categories.unique())\n",
    "display(graphviz.Source(xgboost.to_graphviz(classifier)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "name": "nlp_basics.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "399.533px",
    "width": "431px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": null,
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
